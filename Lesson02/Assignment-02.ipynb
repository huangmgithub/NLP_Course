{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments for Week-02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we learnt what's the search problem and what's the machine leanring. In this assignment, we need you do some more practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Re-code the house price machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Random Choose Method to get optimal *k* and *b*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()  #房价数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'F:\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data[\"data\"], data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n",
       "       6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n",
       "       1.7800e+01, 3.9690e+02, 9.1400e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.31,  7.07,  7.07,  2.18,  2.18,  2.18,  7.87,  7.87,  7.87,\n",
       "        7.87,  7.87,  7.87,  7.87,  8.14,  8.14,  8.14,  8.14,  8.14,\n",
       "        8.14,  8.14,  8.14,  8.14,  8.14,  8.14,  8.14,  8.14,  8.14,\n",
       "        8.14,  8.14,  8.14,  8.14,  8.14,  8.14,  8.14,  8.14,  5.96,\n",
       "        5.96,  5.96,  5.96,  2.95,  2.95,  6.91,  6.91,  6.91,  6.91,\n",
       "        6.91,  6.91,  6.91,  6.91,  6.91,  5.64,  5.64,  5.64,  5.64,\n",
       "        4.  ,  1.22,  0.74,  1.32,  5.13,  5.13,  5.13,  5.13,  5.13,\n",
       "        5.13,  1.38,  3.37,  3.37,  6.07,  6.07,  6.07, 10.81, 10.81,\n",
       "       10.81, 10.81, 12.83, 12.83, 12.83, 12.83, 12.83, 12.83,  4.86,\n",
       "        4.86,  4.86,  4.86,  4.49,  4.49,  4.49,  4.49,  3.41,  3.41,\n",
       "        3.41,  3.41, 15.04, 15.04, 15.04,  2.89,  2.89,  2.89,  2.89,\n",
       "        2.89,  8.56,  8.56,  8.56,  8.56,  8.56,  8.56,  8.56,  8.56,\n",
       "        8.56,  8.56,  8.56, 10.01, 10.01, 10.01, 10.01, 10.01, 10.01,\n",
       "       10.01, 10.01, 10.01, 25.65, 25.65, 25.65, 25.65, 25.65, 25.65,\n",
       "       25.65, 21.89, 21.89, 21.89, 21.89, 21.89, 21.89, 21.89, 21.89,\n",
       "       21.89, 21.89, 21.89, 21.89, 21.89, 21.89, 21.89, 19.58, 19.58,\n",
       "       19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58,\n",
       "       19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58,\n",
       "       19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58, 19.58,\n",
       "       19.58,  4.05,  4.05,  4.05,  4.05,  4.05,  4.05,  4.05,  2.46,\n",
       "        2.46,  2.46,  2.46,  2.46,  2.46,  2.46,  2.46,  3.44,  3.44,\n",
       "        3.44,  3.44,  3.44,  3.44,  2.93,  2.93,  0.46,  1.52,  1.52,\n",
       "        1.52,  1.47,  1.47,  2.03,  2.03,  2.68,  2.68, 10.59, 10.59,\n",
       "       10.59, 10.59, 10.59, 10.59, 10.59, 10.59, 10.59, 10.59, 10.59,\n",
       "       13.89, 13.89, 13.89, 13.89,  6.2 ,  6.2 ,  6.2 ,  6.2 ,  6.2 ,\n",
       "        6.2 ,  6.2 ,  6.2 ,  6.2 ,  6.2 ,  6.2 ,  6.2 ,  6.2 ,  6.2 ,\n",
       "        6.2 ,  6.2 ,  6.2 ,  6.2 ,  4.93,  4.93,  4.93,  4.93,  4.93,\n",
       "        4.93,  5.86,  5.86,  5.86,  5.86,  5.86,  5.86,  5.86,  5.86,\n",
       "        5.86,  5.86,  3.64,  3.64,  3.75,  3.97,  3.97,  3.97,  3.97,\n",
       "        3.97,  3.97,  3.97,  3.97,  3.97,  3.97,  3.97,  3.97,  6.96,\n",
       "        6.96,  6.96,  6.96,  6.96,  6.41,  6.41,  6.41,  6.41,  6.41,\n",
       "        3.33,  3.33,  3.33,  3.33,  1.21,  2.97,  2.25,  1.76,  5.32,\n",
       "        5.32,  5.32,  4.95,  4.95,  4.95, 13.92, 13.92, 13.92, 13.92,\n",
       "       13.92,  2.24,  2.24,  2.24,  6.09,  6.09,  6.09,  2.18,  2.18,\n",
       "        2.18,  2.18,  9.9 ,  9.9 ,  9.9 ,  9.9 ,  9.9 ,  9.9 ,  9.9 ,\n",
       "        9.9 ,  9.9 ,  9.9 ,  9.9 ,  9.9 ,  7.38,  7.38,  7.38,  7.38,\n",
       "        7.38,  7.38,  7.38,  7.38,  3.24,  3.24,  3.24,  6.06,  6.06,\n",
       "        5.19,  5.19,  5.19,  5.19,  5.19,  5.19,  5.19,  5.19,  1.52,\n",
       "        1.89,  3.78,  3.78,  4.39,  4.39,  4.15,  2.01,  1.25,  1.25,\n",
       "        1.69,  1.69,  2.02,  1.91,  1.91, 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 , 18.1 ,\n",
       "       18.1 , 18.1 , 27.74, 27.74, 27.74, 27.74, 27.74,  9.69,  9.69,\n",
       "        9.69,  9.69,  9.69,  9.69,  9.69,  9.69, 11.93, 11.93, 11.93,\n",
       "       11.93, 11.93])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price(fea, k, b):\n",
    "    \"\"\"价格函数，f(x) = k * x + b\"\"\"\n",
    "    return k * fea + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fea_and_price(x):\n",
    "    \"\"\"画出rm和房价关系图\"\"\"\n",
    "    plt.scatter(x, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_fea_and_price(X[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "$$ loss = \\frac{1}{n} \\sum{(y_i - \\hat{y_i})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, y_hat):\n",
    "    \"\"\"损失函数\"\"\"\n",
    "    return sum((y_i - y_hat_i) ** 2 for y_i, y_hat_i in zip(list(y), list(y_hat))) / len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm = X[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def random_learning_function(times):\n",
    "\n",
    "    min_loss = float('inf') #正无穷\n",
    "    best_k = None\n",
    "    best_b = None\n",
    "\n",
    "    for i in range(times):\n",
    "        k = random.random() * 200 - 100\n",
    "        b = random.random() * 200 - 100\n",
    "        price_by_random_k_and_b = [price(r, k, b) for r in X_rm] #随机得来的y_hat\n",
    "\n",
    "        current_loss = loss_function(Y, price_by_random_k_and_b)\n",
    "\n",
    "        if current_loss < min_loss:\n",
    "            min_loss = current_loss\n",
    "\n",
    "            best_k, best_b = k, b\n",
    "            print(\"When time is :%s, get best_k:%s best_b:%s, and loss is:%s\" % (i, best_k, best_b, min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is :0, get best_k:10.175882441183234 best_b:-19.302628090726003, and loss is:533.2978590595221\n",
      "When time is :21, get best_k:-6.503475792135987 best_b:66.7584530836314, and loss is:174.83588847891568\n",
      "When time is :24, get best_k:1.2364493643955115 best_b:17.715103299677537, and loss is:82.80270629326017\n",
      "When time is :52, get best_k:8.393022010385039 best_b:-33.286286802833104, and loss is:53.28557802835524\n",
      "When time is :859, get best_k:7.2938297983080105 best_b:-24.30541505906227, and loss is:46.209939179818605\n"
     ]
    }
   ],
   "source": [
    "random_learning_function(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x25dc1a8f7b8>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 根据上面运行情况，尝试k,b值\n",
    "X_rm = X[:, 5]\n",
    "k = 15\n",
    "b = -68\n",
    "price_by_random_k_and_b = [price(r, k, b) for r in X_rm]\n",
    "\n",
    "draw_fea_and_price(X_rm)\n",
    "plt.scatter(X_rm, price_by_random_k_and_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Supervised Direction to get optimal *k* and *b*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning_function_1(times, scalar):\n",
    "    \"\"\"\n",
    "    times: 次数\n",
    "    scalar：步长\n",
    "    \"\"\"\n",
    "    min_loss = float('inf') #正无穷\n",
    "    best_k = random.random() * 200 - 100\n",
    "    best_b = random.random() * 200 - 100\n",
    "    \n",
    "    # 方向\n",
    "    direction = [ (+1, -1),(+1, +1),(-1, +1),(-1, -1)]\n",
    "\n",
    "    current_direction = random.choice(direction)\n",
    "\n",
    "    for i in range(times):\n",
    "        k_direction, b_direction = current_direction\n",
    "\n",
    "        current_k, current_b = best_k + k_direction * scalar, best_b + b_direction * scalar\n",
    "\n",
    "        price_by_random_k_and_b = [price(r, current_k, current_b) for r in X_rm] #y_hat\n",
    "\n",
    "        current_loss = loss(Y, price_by_random_k_and_b)\n",
    "\n",
    "        if current_loss < min_loss:\n",
    "            min_loss = current_loss\n",
    "            best_k, best_b = current_k, current_b\n",
    "            current_direction = current_direction\n",
    "            \n",
    "            print(\"When time is :%s, get best_k:%s best_b:%s, and loss is:%s\" % (i, best_k, best_b, min_loss))\n",
    "        else:\n",
    "            current_direction = random.choice(direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is :0, get best_k:42.83756138659355 best_b:-87.85201856620323, and loss is:158.83358647016468\n",
      "When time is :6, get best_k:42.637561386593546 best_b:-88.05201856620323, and loss is:157.37665959269424\n",
      "When time is :7, get best_k:42.43756138659354 best_b:-88.25201856620323, and loss is:155.91973271522383\n",
      "When time is :8, get best_k:42.23756138659354 best_b:-88.45201856620324, and loss is:154.46280583775348\n",
      "When time is :9, get best_k:42.03756138659354 best_b:-88.65201856620324, and loss is:153.00587896028293\n",
      "When time is :10, get best_k:41.837561386593535 best_b:-88.85201856620324, and loss is:151.54895208281283\n",
      "When time is :11, get best_k:41.63756138659353 best_b:-89.05201856620324, and loss is:150.09202520534242\n",
      "When time is :12, get best_k:41.43756138659353 best_b:-89.25201856620325, and loss is:148.63509832787196\n",
      "When time is :13, get best_k:41.237561386593526 best_b:-89.45201856620325, and loss is:147.17817145040172\n",
      "When time is :14, get best_k:41.037561386593524 best_b:-89.65201856620325, and loss is:145.72124457293134\n",
      "When time is :15, get best_k:40.83756138659352 best_b:-89.85201856620326, and loss is:144.26431769546087\n",
      "When time is :16, get best_k:40.63756138659352 best_b:-90.05201856620326, and loss is:142.80739081799067\n",
      "When time is :17, get best_k:40.437561386593515 best_b:-90.25201856620326, and loss is:141.35046394052023\n",
      "When time is :18, get best_k:40.23756138659351 best_b:-90.45201856620326, and loss is:139.89353706304965\n",
      "When time is :19, get best_k:40.03756138659351 best_b:-90.65201856620327, and loss is:138.4366101855794\n",
      "When time is :20, get best_k:39.83756138659351 best_b:-90.85201856620327, and loss is:136.97968330810892\n",
      "When time is :21, get best_k:39.637561386593504 best_b:-91.05201856620327, and loss is:135.5227564306386\n",
      "When time is :22, get best_k:39.4375613865935 best_b:-91.25201856620328, and loss is:134.06582955316838\n",
      "When time is :23, get best_k:39.2375613865935 best_b:-91.45201856620328, and loss is:132.60890267569783\n",
      "When time is :24, get best_k:39.037561386593495 best_b:-91.65201856620328, and loss is:131.15197579822743\n",
      "When time is :25, get best_k:38.83756138659349 best_b:-91.85201856620328, and loss is:129.69504892075705\n",
      "When time is :26, get best_k:38.63756138659349 best_b:-92.05201856620329, and loss is:128.23812204328698\n",
      "When time is :27, get best_k:38.43756138659349 best_b:-92.25201856620329, and loss is:126.78119516581631\n",
      "When time is :28, get best_k:38.237561386593484 best_b:-92.4520185662033, and loss is:125.32426828834592\n",
      "When time is :29, get best_k:38.03756138659348 best_b:-92.6520185662033, and loss is:123.86734141087555\n",
      "When time is :30, get best_k:37.83756138659348 best_b:-92.8520185662033, and loss is:122.41041453340517\n",
      "When time is :31, get best_k:37.637561386593475 best_b:-93.0520185662033, and loss is:120.95348765593488\n",
      "When time is :32, get best_k:37.43756138659347 best_b:-93.2520185662033, and loss is:119.49656077846453\n",
      "When time is :33, get best_k:37.23756138659347 best_b:-93.45201856620331, and loss is:118.03963390099399\n",
      "When time is :34, get best_k:37.03756138659347 best_b:-93.65201856620331, and loss is:116.58270702352372\n",
      "When time is :35, get best_k:36.837561386593464 best_b:-93.85201856620331, and loss is:115.12578014605336\n",
      "When time is :36, get best_k:36.63756138659346 best_b:-94.05201856620332, and loss is:113.66885326858302\n",
      "When time is :37, get best_k:36.43756138659346 best_b:-94.25201856620332, and loss is:112.21192639111264\n",
      "When time is :38, get best_k:36.237561386593455 best_b:-94.45201856620332, and loss is:110.75499951364228\n",
      "When time is :39, get best_k:36.03756138659345 best_b:-94.65201856620332, and loss is:109.29807263617177\n",
      "When time is :40, get best_k:35.83756138659345 best_b:-94.85201856620333, and loss is:107.84114575870147\n",
      "When time is :41, get best_k:35.63756138659345 best_b:-95.05201856620333, and loss is:106.38421888123116\n",
      "When time is :42, get best_k:35.437561386593444 best_b:-95.25201856620333, and loss is:104.9272920037608\n",
      "When time is :43, get best_k:35.23756138659344 best_b:-95.45201856620334, and loss is:103.47036512629029\n",
      "When time is :44, get best_k:35.03756138659344 best_b:-95.65201856620334, and loss is:102.01343824881997\n",
      "When time is :45, get best_k:34.837561386593435 best_b:-95.85201856620334, and loss is:100.55651137134959\n",
      "When time is :46, get best_k:34.63756138659343 best_b:-96.05201856620334, and loss is:99.10040529415015\n",
      "When time is :47, get best_k:34.43756138659343 best_b:-96.25201856620335, and loss is:97.64708395027668\n",
      "When time is :48, get best_k:34.23756138659343 best_b:-96.45201856620335, and loss is:96.19376260640315\n",
      "When time is :49, get best_k:34.037561386593424 best_b:-96.65201856620335, and loss is:94.74044126252954\n",
      "When time is :50, get best_k:33.83756138659342 best_b:-96.85201856620336, and loss is:93.287119918656\n",
      "When time is :51, get best_k:33.63756138659342 best_b:-97.05201856620336, and loss is:91.83379857478253\n",
      "When time is :52, get best_k:33.437561386593416 best_b:-97.25201856620336, and loss is:90.38047723090894\n",
      "When time is :53, get best_k:33.23756138659341 best_b:-97.45201856620336, and loss is:88.92715588703531\n",
      "When time is :54, get best_k:33.03756138659341 best_b:-97.65201856620337, and loss is:87.4738345431619\n",
      "When time is :55, get best_k:32.83756138659341 best_b:-97.85201856620337, and loss is:86.02051319928829\n",
      "When time is :56, get best_k:32.637561386593404 best_b:-98.05201856620337, and loss is:84.56719185541475\n",
      "When time is :57, get best_k:32.4375613865934 best_b:-98.25201856620338, and loss is:83.11387051154122\n",
      "When time is :58, get best_k:32.2375613865934 best_b:-98.45201856620338, and loss is:81.6605491676677\n",
      "When time is :59, get best_k:32.037561386593396 best_b:-98.65201856620338, and loss is:80.20722782379417\n",
      "When time is :60, get best_k:31.837561386593396 best_b:-98.85201856620338, and loss is:78.7539064799206\n",
      "When time is :61, get best_k:31.637561386593397 best_b:-99.05201856620339, and loss is:77.30058513604709\n",
      "When time is :62, get best_k:31.437561386593398 best_b:-99.25201856620339, and loss is:75.85085556659973\n",
      "When time is :63, get best_k:31.2375613865934 best_b:-99.45201856620339, and loss is:74.40137849150086\n",
      "When time is :64, get best_k:31.0375613865934 best_b:-99.6520185662034, and loss is:72.95190141640211\n",
      "When time is :65, get best_k:30.8375613865934 best_b:-99.8520185662034, and loss is:71.5024243413032\n",
      "When time is :66, get best_k:30.6375613865934 best_b:-100.0520185662034, and loss is:70.05294726620444\n",
      "When time is :67, get best_k:30.4375613865934 best_b:-100.2520185662034, and loss is:68.60347019110567\n",
      "When time is :68, get best_k:30.237561386593402 best_b:-100.4520185662034, and loss is:67.15467034317997\n",
      "When time is :69, get best_k:30.037561386593403 best_b:-100.65201856620341, and loss is:65.70991263567021\n",
      "When time is :70, get best_k:29.837561386593404 best_b:-100.85201856620341, and loss is:64.26515492816029\n",
      "When time is :71, get best_k:29.637561386593404 best_b:-101.05201856620342, and loss is:62.82039722065041\n",
      "When time is :72, get best_k:29.437561386593405 best_b:-101.25201856620342, and loss is:61.375639513140555\n",
      "When time is :73, get best_k:29.237561386593406 best_b:-101.45201856620342, and loss is:59.93088180563063\n",
      "When time is :74, get best_k:29.037561386593406 best_b:-101.65201856620342, and loss is:58.486124098120726\n",
      "When time is :75, get best_k:28.837561386593407 best_b:-101.85201856620343, and loss is:57.04136639061086\n",
      "When time is :76, get best_k:28.637561386593408 best_b:-102.05201856620343, and loss is:55.59660868310104\n",
      "When time is :77, get best_k:28.43756138659341 best_b:-102.25201856620343, and loss is:54.15185097559114\n",
      "When time is :78, get best_k:28.23756138659341 best_b:-102.45201856620344, and loss is:52.70709326808126\n",
      "When time is :79, get best_k:28.03756138659341 best_b:-102.65201856620344, and loss is:51.264045400683926\n",
      "When time is :80, get best_k:27.83756138659341 best_b:-102.85201856620344, and loss is:49.823349353253086\n",
      "When time is :81, get best_k:27.63756138659341 best_b:-103.05201856620344, and loss is:48.38497658467005\n",
      "When time is :82, get best_k:27.437561386593412 best_b:-103.25201856620345, and loss is:46.94834219731824\n",
      "When time is :83, get best_k:27.237561386593413 best_b:-103.45201856620345, and loss is:45.511707809966474\n",
      "When time is :84, get best_k:27.037561386593413 best_b:-103.65201856620345, and loss is:44.07507342261469\n",
      "When time is :85, get best_k:26.837561386593414 best_b:-103.85201856620345, and loss is:42.63843903526288\n",
      "When time is :86, get best_k:26.637561386593415 best_b:-104.05201856620346, and loss is:41.20180464791119\n",
      "When time is :87, get best_k:26.437561386593416 best_b:-104.25201856620346, and loss is:39.76517026055938\n",
      "When time is :88, get best_k:26.237561386593416 best_b:-104.45201856620346, and loss is:38.33340120873731\n",
      "When time is :89, get best_k:26.037561386593417 best_b:-104.65201856620347, and loss is:36.90665061585194\n",
      "When time is :90, get best_k:25.837561386593418 best_b:-104.85201856620347, and loss is:35.48303658592922\n",
      "When time is :91, get best_k:25.63756138659342 best_b:-105.05201856620347, and loss is:34.06052947130473\n",
      "When time is :92, get best_k:25.43756138659342 best_b:-105.25201856620347, and loss is:32.641601018358244\n",
      "When time is :93, get best_k:25.23756138659342 best_b:-105.45201856620348, and loss is:31.22380773772584\n",
      "When time is :94, get best_k:25.03756138659342 best_b:-105.65201856620348, and loss is:29.806087725817317\n",
      "When time is :95, get best_k:24.83756138659342 best_b:-105.85201856620348, and loss is:28.399606546591848\n",
      "When time is :96, get best_k:24.637561386593422 best_b:-106.05201856620349, and loss is:26.996348443825063\n",
      "When time is :97, get best_k:24.437561386593423 best_b:-106.25201856620349, and loss is:25.598853026315595\n",
      "When time is :98, get best_k:24.237561386593423 best_b:-106.45201856620349, and loss is:24.210750500215134\n",
      "When time is :99, get best_k:24.037561386593424 best_b:-106.6520185662035, and loss is:22.831316466209547\n",
      "When time is :100, get best_k:23.837561386593425 best_b:-106.8520185662035, and loss is:21.473614522112587\n",
      "When time is :101, get best_k:23.637561386593426 best_b:-107.0520185662035, and loss is:20.13448064655237\n",
      "When time is :102, get best_k:23.437561386593426 best_b:-107.2520185662035, and loss is:18.80511896807458\n",
      "When time is :103, get best_k:23.237561386593427 best_b:-107.4520185662035, and loss is:17.506719067209538\n",
      "When time is :104, get best_k:23.037561386593428 best_b:-107.65201856620351, and loss is:16.219337824143214\n",
      "When time is :105, get best_k:22.83756138659343 best_b:-107.85201856620351, and loss is:14.943108996353972\n",
      "When time is :106, get best_k:22.63756138659343 best_b:-108.05201856620351, and loss is:13.683557890940568\n",
      "When time is :107, get best_k:22.43756138659343 best_b:-108.25201856620352, and loss is:12.475166467542243\n",
      "When time is :108, get best_k:22.23756138659343 best_b:-108.45201856620352, and loss is:11.34990084930677\n",
      "When time is :109, get best_k:22.03756138659343 best_b:-108.65201856620352, and loss is:10.325751412387218\n",
      "When time is :110, get best_k:21.837561386593432 best_b:-108.85201856620353, and loss is:9.429619775729828\n",
      "When time is :111, get best_k:21.637561386593433 best_b:-109.05201856620353, and loss is:8.691020914760035\n",
      "When time is :112, get best_k:21.437561386593433 best_b:-109.25201856620353, and loss is:8.139633613219775\n",
      "When time is :113, get best_k:21.237561386593434 best_b:-109.45201856620353, and loss is:7.76067400956896\n",
      "When time is :114, get best_k:21.037561386593435 best_b:-109.65201856620354, and loss is:7.54343824277975\n",
      "When time is :115, get best_k:20.837561386593435 best_b:-109.85201856620354, and loss is:7.505500895058657\n"
     ]
    }
   ],
   "source": [
    "supervised_learning_function_1(2500, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Gradient Descent to get optimal *k* and *b*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Lesson Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Try different Loss function and learning rate.\n",
    "\n",
    "For example, you can change the loss function: $Loss = \\frac{1}{n} sum({y_i - \\hat{y_i}})^2$ to $Loss = \\frac{1}{n} sum(|{y_i - \\hat{y_i}}|)$\n",
    "\n",
    "And you can change the learning rate and observe the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y, y_hat):\n",
    "    \"\"\"a new loss function\"\"\"\n",
    "    return sum(abs(y_i - y_hat_i) for y_i, y_hat_i in zip(list(y), list(y_hat))) / len(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_learning_function_2(times, scalar):\n",
    "    \"\"\"\n",
    "    times: 次数\n",
    "    scalar：步长\n",
    "    \"\"\"\n",
    "    min_loss = float('inf') #正无穷\n",
    "    best_k = random.random() * 200 - 100\n",
    "    best_b = random.random() * 200 - 100\n",
    "    \n",
    "    # 方向\n",
    "    direction = [  (+1, -1),(+1, +1),(-1, +1),(-1, -1)]\n",
    "\n",
    "    current_direction = random.choice(direction)\n",
    "\n",
    "    for i in range(times):\n",
    "        k_direction, b_direction = current_direction\n",
    "\n",
    "        current_k, current_b = best_k + k_direction * scalar, best_b + b_direction * scalar\n",
    "\n",
    "        price_by_random_k_and_b = [price(r, current_k, current_b) for r in X_rm] #y_hat\n",
    "\n",
    "        current_loss = loss(Y, price_by_random_k_and_b)\n",
    "\n",
    "        if current_loss < min_loss:\n",
    "            min_loss = current_loss\n",
    "\n",
    "            best_k, best_b = current_k, current_b\n",
    "            current_direction = current_direction\n",
    "            print(\"When time is :%s, get best_k:%s best_b:%s, and loss is:%s\" % (i, best_k, best_b, min_loss))\n",
    "        else:\n",
    "            current_direction = random.choice(direction) # 缺点：随机取方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When time is :0, get best_k:-23.803600733569656 best_b:-80.83789378631253, and loss is:252.9676278234072\n",
      "When time is :3, get best_k:-23.503600733569655 best_b:-80.53789378631254, and loss is:250.7822375072016\n",
      "When time is :4, get best_k:-23.203600733569655 best_b:-80.23789378631254, and loss is:248.5968471909958\n",
      "When time is :5, get best_k:-22.903600733569654 best_b:-79.93789378631254, and loss is:246.41145687479042\n",
      "When time is :6, get best_k:-22.603600733569653 best_b:-79.63789378631255, and loss is:244.22606655858505\n",
      "When time is :7, get best_k:-22.303600733569652 best_b:-79.33789378631255, and loss is:242.0406762423795\n",
      "When time is :8, get best_k:-22.00360073356965 best_b:-79.03789378631255, and loss is:239.85528592617402\n",
      "When time is :9, get best_k:-21.70360073356965 best_b:-78.73789378631255, and loss is:237.66989560996848\n",
      "When time is :10, get best_k:-21.40360073356965 best_b:-78.43789378631256, and loss is:235.48450529376285\n",
      "When time is :11, get best_k:-21.10360073356965 best_b:-78.13789378631256, and loss is:233.29911497755734\n",
      "When time is :12, get best_k:-20.80360073356965 best_b:-77.83789378631256, and loss is:231.11372466135168\n",
      "When time is :13, get best_k:-20.503600733569648 best_b:-77.53789378631257, and loss is:228.92833434514614\n",
      "When time is :14, get best_k:-20.203600733569647 best_b:-77.23789378631257, and loss is:226.74294402894054\n",
      "When time is :15, get best_k:-19.903600733569647 best_b:-76.93789378631257, and loss is:224.55755371273497\n",
      "When time is :16, get best_k:-19.603600733569646 best_b:-76.63789378631257, and loss is:222.3721633965297\n",
      "When time is :17, get best_k:-19.303600733569645 best_b:-76.33789378631258, and loss is:220.1867730803241\n",
      "When time is :18, get best_k:-19.003600733569645 best_b:-76.03789378631258, and loss is:218.00138276411843\n",
      "When time is :19, get best_k:-18.703600733569644 best_b:-75.73789378631258, and loss is:215.81599244791278\n",
      "When time is :20, get best_k:-18.403600733569643 best_b:-75.43789378631259, and loss is:213.63060213170743\n",
      "When time is :21, get best_k:-18.103600733569643 best_b:-75.13789378631259, and loss is:211.44521181550212\n",
      "When time is :22, get best_k:-17.803600733569642 best_b:-74.83789378631259, and loss is:209.25982149929658\n",
      "When time is :23, get best_k:-17.50360073356964 best_b:-74.5378937863126, and loss is:207.07443118309095\n",
      "When time is :24, get best_k:-17.20360073356964 best_b:-74.2378937863126, and loss is:204.8890408668853\n",
      "When time is :25, get best_k:-16.90360073356964 best_b:-73.9378937863126, and loss is:202.70365055068007\n",
      "When time is :26, get best_k:-16.60360073356964 best_b:-73.6378937863126, and loss is:200.51826023447472\n",
      "When time is :27, get best_k:-16.30360073356964 best_b:-73.3378937863126, and loss is:198.33286991826878\n",
      "When time is :28, get best_k:-16.003600733569638 best_b:-73.03789378631261, and loss is:196.14747960206304\n",
      "When time is :29, get best_k:-15.703600733569637 best_b:-72.73789378631261, and loss is:193.96208928585773\n",
      "When time is :30, get best_k:-15.403600733569636 best_b:-72.43789378631261, and loss is:191.77669896965236\n",
      "When time is :31, get best_k:-15.103600733569635 best_b:-72.13789378631262, and loss is:189.59130865344633\n",
      "When time is :32, get best_k:-14.803600733569635 best_b:-71.83789378631262, and loss is:187.40591833724122\n",
      "When time is :33, get best_k:-14.503600733569634 best_b:-71.53789378631262, and loss is:185.2205280210356\n",
      "When time is :34, get best_k:-14.203600733569633 best_b:-71.23789378631263, and loss is:183.03513770483002\n",
      "When time is :35, get best_k:-13.903600733569633 best_b:-70.93789378631263, and loss is:180.8497473886245\n",
      "When time is :36, get best_k:-13.603600733569632 best_b:-70.63789378631263, and loss is:178.6643570724189\n",
      "When time is :37, get best_k:-13.303600733569631 best_b:-70.33789378631263, and loss is:176.47896675621334\n",
      "When time is :38, get best_k:-13.00360073356963 best_b:-70.03789378631264, and loss is:174.29357644000805\n",
      "When time is :39, get best_k:-12.70360073356963 best_b:-69.73789378631264, and loss is:172.10818612380237\n",
      "When time is :40, get best_k:-12.403600733569629 best_b:-69.43789378631264, and loss is:169.92279580759677\n",
      "When time is :41, get best_k:-12.103600733569628 best_b:-69.13789378631265, and loss is:167.73740549139114\n",
      "When time is :42, get best_k:-11.803600733569628 best_b:-68.83789378631265, and loss is:165.55201517518546\n",
      "When time is :43, get best_k:-11.503600733569627 best_b:-68.53789378631265, and loss is:163.36662485898006\n",
      "When time is :44, get best_k:-11.203600733569626 best_b:-68.23789378631265, and loss is:161.18123454277446\n",
      "When time is :45, get best_k:-10.903600733569625 best_b:-67.93789378631266, and loss is:158.99584422656912\n",
      "When time is :46, get best_k:-10.603600733569625 best_b:-67.63789378631266, and loss is:156.8104539103637\n",
      "When time is :47, get best_k:-10.303600733569624 best_b:-67.33789378631266, and loss is:154.62506359415806\n",
      "When time is :48, get best_k:-10.003600733569623 best_b:-67.03789378631267, and loss is:152.4396732779524\n",
      "When time is :49, get best_k:-9.703600733569623 best_b:-66.73789378631267, and loss is:150.25428296174692\n",
      "When time is :50, get best_k:-9.403600733569622 best_b:-66.43789378631267, and loss is:148.06889264554135\n",
      "When time is :51, get best_k:-9.103600733569621 best_b:-66.13789378631267, and loss is:145.8835023293357\n",
      "When time is :52, get best_k:-8.80360073356962 best_b:-65.83789378631268, and loss is:143.6981120131305\n",
      "When time is :53, get best_k:-8.50360073356962 best_b:-65.53789378631268, and loss is:141.51272169692479\n",
      "When time is :54, get best_k:-8.203600733569619 best_b:-65.23789378631268, and loss is:139.32733138071922\n",
      "When time is :55, get best_k:-7.903600733569619 best_b:-64.93789378631269, and loss is:137.14194106451376\n",
      "When time is :56, get best_k:-7.603600733569619 best_b:-64.63789378631269, and loss is:134.9565507483082\n",
      "When time is :57, get best_k:-7.30360073356962 best_b:-64.33789378631269, and loss is:132.7711604321028\n",
      "When time is :58, get best_k:-7.00360073356962 best_b:-64.0378937863127, and loss is:130.58577011589716\n",
      "When time is :59, get best_k:-6.70360073356962 best_b:-63.737893786312696, and loss is:128.40037979969162\n",
      "When time is :60, get best_k:-6.40360073356962 best_b:-63.4378937863127, and loss is:126.21498948348612\n",
      "When time is :61, get best_k:-6.10360073356962 best_b:-63.1378937863127, and loss is:124.02959916728058\n",
      "When time is :62, get best_k:-5.8036007335696205 best_b:-62.837893786312705, and loss is:121.84420885107495\n",
      "When time is :63, get best_k:-5.503600733569621 best_b:-62.53789378631271, and loss is:119.6588185348694\n",
      "When time is :64, get best_k:-5.203600733569621 best_b:-62.23789378631271, and loss is:117.47342821866394\n",
      "When time is :65, get best_k:-4.903600733569621 best_b:-61.93789378631271, and loss is:115.28803790245846\n",
      "When time is :66, get best_k:-4.603600733569621 best_b:-61.637893786312716, and loss is:113.10264758625283\n",
      "When time is :67, get best_k:-4.303600733569621 best_b:-61.33789378631272, and loss is:110.91725727004733\n",
      "When time is :68, get best_k:-4.0036007335696215 best_b:-61.03789378631272, and loss is:108.73186695384179\n",
      "When time is :69, get best_k:-3.7036007335696217 best_b:-60.737893786312725, and loss is:106.54647663763639\n",
      "When time is :70, get best_k:-3.403600733569622 best_b:-60.43789378631273, and loss is:104.3610863214308\n",
      "When time is :71, get best_k:-3.103600733569622 best_b:-60.13789378631273, and loss is:102.17569600522522\n",
      "When time is :72, get best_k:-2.8036007335696222 best_b:-59.83789378631273, and loss is:99.99030568901976\n",
      "When time is :73, get best_k:-2.5036007335696224 best_b:-59.537893786312736, and loss is:97.80491537281412\n",
      "When time is :74, get best_k:-2.2036007335696226 best_b:-59.23789378631274, and loss is:95.61952505660858\n",
      "When time is :75, get best_k:-1.9036007335696226 best_b:-58.93789378631274, and loss is:93.43413474040311\n",
      "When time is :76, get best_k:-1.6036007335696225 best_b:-58.637893786312745, and loss is:91.24874442419775\n",
      "When time is :77, get best_k:-1.3036007335696225 best_b:-58.33789378631275, and loss is:89.06335410799213\n",
      "When time is :78, get best_k:-1.0036007335696224 best_b:-58.03789378631275, and loss is:86.87796379178661\n",
      "When time is :79, get best_k:-0.7036007335696224 best_b:-57.73789378631275, and loss is:84.69257347558096\n",
      "When time is :80, get best_k:-0.4036007335696224 best_b:-57.437893786312756, and loss is:82.50718315937549\n",
      "When time is :81, get best_k:-0.1036007335696224 best_b:-57.13789378631276, and loss is:80.32179284317\n",
      "When time is :82, get best_k:0.19639926643037758 best_b:-56.83789378631276, and loss is:78.13640252696445\n",
      "When time is :83, get best_k:0.4963992664303776 best_b:-56.537893786312765, and loss is:75.95101221075885\n",
      "When time is :84, get best_k:0.7963992664303776 best_b:-56.23789378631277, and loss is:73.76562189455333\n",
      "When time is :85, get best_k:1.0963992664303777 best_b:-55.93789378631277, and loss is:71.58023157834783\n",
      "When time is :86, get best_k:1.3963992664303777 best_b:-55.63789378631277, and loss is:69.39484126214224\n",
      "When time is :87, get best_k:1.6963992664303778 best_b:-55.337893786312776, and loss is:67.20945094593678\n",
      "When time is :88, get best_k:1.9963992664303778 best_b:-55.03789378631278, and loss is:65.02406062973122\n",
      "When time is :89, get best_k:2.296399266430378 best_b:-54.73789378631278, and loss is:62.83867031352568\n",
      "When time is :90, get best_k:2.5963992664303777 best_b:-54.437893786312785, and loss is:60.65327999732013\n",
      "When time is :91, get best_k:2.8963992664303775 best_b:-54.13789378631279, and loss is:58.46788968111466\n",
      "When time is :92, get best_k:3.1963992664303773 best_b:-53.83789378631279, and loss is:56.28249936490913\n",
      "When time is :93, get best_k:3.496399266430377 best_b:-53.53789378631279, and loss is:54.09710904870356\n",
      "When time is :94, get best_k:3.796399266430377 best_b:-53.237893786312796, and loss is:51.91171873249801\n",
      "When time is :95, get best_k:4.096399266430377 best_b:-52.9378937863128, and loss is:49.72632841629253\n",
      "When time is :96, get best_k:4.396399266430377 best_b:-52.6378937863128, and loss is:47.54093810008701\n",
      "When time is :97, get best_k:4.696399266430377 best_b:-52.337893786312804, and loss is:45.35554778388146\n",
      "When time is :98, get best_k:4.996399266430377 best_b:-52.03789378631281, and loss is:43.170157467675956\n",
      "When time is :99, get best_k:5.2963992664303765 best_b:-51.73789378631281, and loss is:40.98476715147042\n",
      "When time is :100, get best_k:5.596399266430376 best_b:-51.43789378631281, and loss is:38.799376835264866\n",
      "When time is :101, get best_k:5.896399266430376 best_b:-51.137893786312816, and loss is:36.61398651905934\n",
      "When time is :102, get best_k:6.196399266430376 best_b:-50.83789378631282, and loss is:34.42859620285381\n",
      "When time is :103, get best_k:6.496399266430376 best_b:-50.53789378631282, and loss is:32.24320588664828\n",
      "When time is :104, get best_k:6.796399266430376 best_b:-50.237893786312824, and loss is:30.05781557044277\n",
      "When time is :105, get best_k:7.096399266430375 best_b:-49.93789378631283, and loss is:27.872425254237218\n",
      "When time is :106, get best_k:7.396399266430375 best_b:-49.63789378631283, and loss is:25.687034938031715\n",
      "When time is :107, get best_k:7.696399266430375 best_b:-49.33789378631283, and loss is:23.50164462182616\n",
      "When time is :108, get best_k:7.996399266430375 best_b:-49.037893786312836, and loss is:21.316254305620642\n",
      "When time is :109, get best_k:8.296399266430376 best_b:-48.73789378631284, and loss is:19.139689198156457\n",
      "When time is :110, get best_k:8.596399266430376 best_b:-48.43789378631284, and loss is:16.986529518749276\n",
      "When time is :111, get best_k:8.896399266430377 best_b:-48.137893786312844, and loss is:14.860116198210328\n",
      "When time is :112, get best_k:9.196399266430378 best_b:-47.83789378631285, and loss is:12.788494474996522\n",
      "When time is :113, get best_k:9.496399266430378 best_b:-47.53789378631285, and loss is:10.818993130907192\n",
      "When time is :114, get best_k:9.79639926643038 best_b:-47.23789378631285, and loss is:8.990096175645755\n",
      "When time is :115, get best_k:10.09639926643038 best_b:-46.937893786312856, and loss is:7.336706261416658\n",
      "When time is :116, get best_k:10.39639926643038 best_b:-46.63789378631286, and loss is:5.925722341201673\n",
      "When time is :117, get best_k:10.696399266430381 best_b:-46.33789378631286, and loss is:4.824913990585202\n",
      "When time is :118, get best_k:10.996399266430382 best_b:-46.037893786312864, and loss is:4.484056237229206\n"
     ]
    }
   ],
   "source": [
    "supervised_learning_function_1(2000, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Answer following questions:\n",
    "\n",
    "\n",
    "###### 1. Why do we need machine learning methods instead of creating a complicated formula?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans : 1.构造一个复杂的函数是比较难 2. 数据不断在变化，对于新的数据，给定函数得到的结果一般来说不准确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.  Wha't's the disadvantages of `the 1st Random Choosen` methods in our course? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 随机的k,b构造的函数所得到的的结果好坏都是随机的，没有优化的方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Is the `2nd method supervised direction` better than 1st one?  What's the disadvantages of `the 2nd supversied directin` method? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 第二种方法好于第一种方法，缺点：1.多元或者多变量函数，方向组合变的更大更复杂 2.对于min_loss条件不成立时，direction取随机也是无优化方向的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Why do we use `Derivative / Gredient` to fit a target function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 待补充。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. In the words 'Gredient Descent', what's the `Gredient` and what's the `Descent`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 待补充。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. What's the advantages of `the 3rd gradient descent method` compared to the previous methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 待补充。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 7. Using the simple words to describe: What's the machine leanring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 待补充。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finish the search problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please using the search policy to implement an agent. This agent receives two input, one is @param start station and the other is @param destination. Your agent should give the optimal route based on Beijing Subway system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Deadline: 2019-July-13\n",
    "\n",
    ">Submit: Submit the source code and result to github. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1562414356407&di=b57814aafd215bb8b8d9d8cd37c573d6&imgtype=0&src=http%3A%2F%2Fcli.clewm.net%2Ffile%2F2015%2F03%2F24%2F174ed60082b8422ac0636cfd3efb9e7f.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataflow: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.\tGet data from web page.\n",
    "\n",
    "> a.\tGet web page source from: https://baike.baidu.com/item/%E5%8C%97%E4%BA%AC%E5%9C%B0%E9%93%81/408485\n",
    "\n",
    "> b.\tYou may need @package **requests**[https://2.python-requests.org/en/master/] page to get the response via url\n",
    "\n",
    "> c.\tYou may need save the page source to file system.\n",
    "\n",
    "> d.\tThe target of this step is to get station information of all the subway lines;\n",
    "\n",
    "> e.\tYou may need install @package beautiful soup[https://www.crummy.com/software/BeautifulSoup/bs4/doc/]  to get the url information, or just use > Regular Expression to get the url.  Our recommendation is that using the Regular Expression and BeautiflSoup both. \n",
    "\n",
    "> f.\tYou may need BFS to get all the related page url from one url. \n",
    "Question: Why do we use BFS to traverse web page (or someone said, build a web spider)?  Can DFS do this job? which is better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.\tPreprocessing data from page source.\n",
    "\n",
    "> a.\tBased on the page source gotten from url. You may need some more preprocessing of the page. \n",
    "\n",
    "> b.\tthe Regular Expression you may need to process the text information.\n",
    "\n",
    "> c.\tYou may need @package networkx, @package matplotlib to visualize data. \n",
    "\n",
    "> d.\tYou should build a dictionary or graph which could represent the connection information of Beijing subway routes. \n",
    "\n",
    "> e.\tYou may need the defaultdict, set data structures to implement this procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Build the search agent\n",
    "\n",
    "> Build the search agent based on the graph we build.\n",
    "\n",
    "for example, when you run: \n",
    "\n",
    "```python\n",
    ">>> search('奥体中心', '天安门') \n",
    "```\n",
    "you need get the result: \n",
    "\n",
    "奥体中心-> A -> B -> C -> ... -> 天安门\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （Optional）Create different policies for transfer system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下部门为可选部分，请酌情完成。 并不要求全部同学完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As much as you can to use the already implemented search agent. You just need to define the **is_goal()**, **get_successor()**, **strategy()** three functions. \n",
    "\n",
    "> a.\tDefine different policies for transfer system. \n",
    "\n",
    "> b.\tSuch as Shortest Path Priority（路程最短优先）, Minimum Transfer Priority(最少换乘优先), Comprehensive Priority(综合优先)\n",
    "\n",
    "> c.\tImplement Continuous transfer. Based on the Agent you implemented, please add this feature: Besides the @param start and @param destination two stations, add some more stations, we called @param by_way, it means, our path should from the start and end, but also include the  @param by_way stations. \n",
    "\n",
    "e.g \n",
    "```\n",
    "1. Input:  start=A,  destination=B, by_way=[C] \n",
    "    Output: [A, … .., C, …. B]\n",
    "2. Input: start=A, destination=B, by_way=[C, D, E]\n",
    "    Output: [A … C … E … D … B]  \n",
    "    # based on your policy, the E station could be reached firstly. \n",
    "![image.png](attachment:image.png)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.\tTest your result with commercial applications. \n",
    "\n",
    "将你的结果和高德地图或者百度地图进行比较，如果有不同，请分析原因\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恭喜，完成本次课程，你对常用的人工智能方法以及有一定的了解了。基于规则的，基于概率模型的，基于搜索的，基于机器学习的。 可以说，我们现在通常见到的方法都能够归属到这几类方法中。 这就是**人工智能**，并没有很难是吧？ 继续加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1562415163815&di=4b29a2a863a8285212033760f288ed7a&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20180710%2F8704194a1d7f46a383ddc29d40c9bca5.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
